{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0e47664dab37355857d58ec29513492f53a294cb5e9a32075fd110bf6e862dd2a",
   "display_name": "Python 3.8.5 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "from nltk.lm import Vocabulary\n",
    "from nltk.lm.models import MLE\n",
    "from nltk.util import ngrams\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 3\n",
    "filepath = \"text/peachy/peachy-4304732.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"ja_ginza\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "女性 NOUN\nを ADP\n潤す VERB\n新た ADJ\nな AUX\n注目 NOUN\nワード NOUN\nは ADP\n“ PUNCT\nアミノ NOUN\n酸 NOUN\n” PUNCT\n"
     ]
    }
   ],
   "source": [
    "for token in nlp(sentences[0]):\n",
    "    print(token.text, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "poss = []\n",
    "with open(filepath, \"r\") as f:\n",
    "    for line in f.readlines()[2:]:\n",
    "        line = line.strip()\n",
    "        if len(line) == 0:\n",
    "            continue\n",
    "        doc = nlp(line)\n",
    "        s = []\n",
    "        pos = []\n",
    "        for token in doc:\n",
    "            s.append(token.text)\n",
    "            pos.append(token.pos_)\n",
    "\n",
    "        sentences.append(s)\n",
    "        poss.append(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['女性', 'を', '潤す', '新た', 'な', '注目', 'ワード', 'は', '“', 'アミノ', '酸', '”']"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = Vocabulary(itertools.chain.from_iterable(sentences))\n",
    "word_ngram = [ngrams(sentence, N) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('女性', 'を', '潤す'), ('を', '潤す', '新た'), ('潤す', '新た', 'な')]"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "list(ngrams(sentences[0], N))[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = MLE(order=N, vocabulary=vocabulary)\n",
    "lm.fit(word_ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "は: 1.0\n"
     ]
    }
   ],
   "source": [
    "context = (\"注目\", \"ワード\")\n",
    "for word in lm.context_counts(lm.vocab.lookup(context)):\n",
    "    print(f\"{word}: {lm.score(word, context)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_vocabulary = Vocabulary(itertools.chain.from_iterable(poss))\n",
    "pos_ngram = [ngrams(pos, N) for pos in poss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('NOUN', 'ADP', 'VERB'), ('ADP', 'VERB', 'ADJ'), ('VERB', 'ADJ', 'AUX')]"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "list(ngrams(poss[0], N))[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_lm = MLE(order=N, vocabulary=pos_vocabulary)\n",
    "pos_lm.fit(pos_ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "NOUN: 0.45714285714285713\nVERB: 0.35714285714285715\nPUNCT: 0.07142857142857142\nADJ: 0.02857142857142857\nADP: 0.02857142857142857\nADV: 0.014285714285714285\nAUX: 0.014285714285714285\nPROPN: 0.014285714285714285\nNUM: 0.014285714285714285\n"
     ]
    }
   ],
   "source": [
    "context = (\"NOUN\", \"ADP\")\n",
    "for pos in pos_lm.context_counts(pos_lm.vocab.lookup(context)):\n",
    "    print(f\"{pos}: {pos_lm.score(pos, context)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('新た', 'な', '注目'), ('な', '注目', 'ワード')]"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "text = \"新たな注目ワード\"\n",
    "tokens = [token.text for token in nlp(text)]\n",
    "list(ngrams(tokens, N))[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_contexts = list(ngrams(tokens, N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "('新た', 'な', '注目'): 1.0\n('な', '注目', 'ワード'): 1.0\n"
     ]
    }
   ],
   "source": [
    "scores = [0 for _ in range(len(tokens))]\n",
    "i = 0\n",
    "tp = 0\n",
    "for context in test_contexts:\n",
    "    p = lm.score(context[-1], context[:-1])\n",
    "    print(f\"{context}: {p}\")\n",
    "    if p <= tp:\n",
    "        for j in range(N):\n",
    "            scores[i+j] -= 1\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}